{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ae3f60-77c6-48e5-8b33-61f8b86dd8e3",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d07f8-bc47-439d-8c28-d9e5935b6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76500c-18c3-4fde-97f6-56ae5b8aba46",
   "metadata": {},
   "source": [
    "# Mount Google Drive and Download NLTK Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19546b78-6863-4caa-8e83-f279edc331a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d54f45-b478-4cb9-bb23-d19983029111",
   "metadata": {},
   "source": [
    "# Load and Preprocess the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d5bd7-a09d-4e11-90aa-a058edd1f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/NLP Mental Health Detector/Datasets/data_to_be_cleansed.csv')\n",
    "df = df.dropna(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73276d0-aa98-49a5-bfd5-32aa25a45469",
   "metadata": {},
   "source": [
    "# Define Text Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65a079-e3b5-485d-a8be-0e88dbf41eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3c08c-f31b-42c2-aaa9-1698fe2dfc06",
   "metadata": {},
   "source": [
    "# Label Mapping and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62d191-0526-41da-ae01-796bce1dea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 'stress', 1: 'depression', 2: 'bipolar disorder', 3: 'personality disorder', 4: 'anxiety'}\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# Split the data\n",
    "X = df['text'].tolist()\n",
    "y = df['target'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a621bf-a3ce-4d81-a6f6-0ab2d77c39a4",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance with Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff87eb-0493-4e60-b1cc-2ebf9cb402b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling to handle class imbalance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(np.array(X).reshape(-1, 1), y)\n",
    "X_resampled = X_resampled.flatten().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c41ad-8950-4707-bb0b-c9c9c550606f",
   "metadata": {},
   "source": [
    "# Initialize RoBERTa Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadaf0f-0048-4fbb-b48f-13221b65cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5bc90e-b2bd-47f8-b600-4d7c5ea4f14e",
   "metadata": {},
   "source": [
    "# Define the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ba6f4-25d9-47a2-be03-4f6c8123a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx] if self.texts[idx] is not None else \"\"\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e6f58-f8d5-4b2a-91b9-65c386555a75",
   "metadata": {},
   "source": [
    "# Define the Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529f177-f0f9-49c7-b78b-a6ae6b68a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce09033-def7-436f-9dde-68df10b960c3",
   "metadata": {},
   "source": [
    "# Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624034d9-9483-4962-9b3d-42db6af6a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65e63e-0f60-432f-b755-25cbd5b034e4",
   "metadata": {},
   "source": [
    "# Implement K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da592a-b906-46fb-ab3b-43ee1f64b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement k-fold cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_resampled, y_resampled), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "    train_texts = [X_resampled[i] for i in train_idx]\n",
    "    train_labels = [y_resampled[i] for i in train_idx]\n",
    "    val_texts = [X_resampled[i] for i in val_idx]\n",
    "    val_labels = [y_resampled[i] for i in val_idx]\n",
    "\n",
    "    train_dataset = MentalHealthDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = MentalHealthDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    num_epochs = 3\n",
    "    num_training_steps = num_epochs * len(train_loader)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        train_loss = train(model, train_loader, optimizer, scheduler, device)\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "\n",
    "        val_predictions, val_true_labels = evaluate(model, val_loader, device)\n",
    "\n",
    "        print(\"\\nValidation Classification Report:\")\n",
    "        print(classification_report(val_true_labels, val_predictions, target_names=[label_map[i] for i in range(5)]))\n",
    "\n",
    "        print(\"\\nValidation Confusion Matrix:\")\n",
    "        print(confusion_matrix(val_true_labels, val_predictions))\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Save the model for each fold\n",
    "    torch.save(model.state_dict(), f'mental_health_roberta_model_fold_{fold}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce14d26-8620-45e1-88b0-6a959fe753b0",
   "metadata": {},
   "source": [
    "# Final Evaluation on a Separate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d747d-de35-411a-9c7c-38b0984999ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on a separate test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "test_dataset = MentalHealthDataset(X_test, y_test, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load the best model (you may need to choose the best fold based on validation results)\n",
    "best_model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)\n",
    "best_model.load_state_dict(torch.load('mental_health_roberta_model_fold_1.pth'))\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "test_predictions, test_true_labels = evaluate(best_model, test_loader, device)\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(test_true_labels, test_predictions, target_names=[label_map[i] for i in range(5)]))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(test_true_labels, test_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
