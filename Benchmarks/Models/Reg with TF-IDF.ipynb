{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79631914-1519-4a25-a477-db367e890df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers torch\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25258a3f-8f8d-45a6-b8e1-ae0113f2c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "from google.colab import drive\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Modified preprocess function\n",
    "def preprocess_function(examples):\n",
    "    # Ensure 'text' is a list of strings\n",
    "    texts = [str(text) for text in examples[\"text\"]]\n",
    "    return tokenizer(texts, truncation=True, padding=True)\n",
    "\n",
    "# Load the single dataset\n",
    "data_df = pd.read_csv(\"/content/drive/MyDrive/NLP Mental Health Detector/Datasets/data_to_be_cleansed.csv\")\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(data_df, test_size=0.4, random_state=42, stratify=data_df[\"target\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"target\"])\n",
    "\n",
    "# Create datasets from the dataframes\n",
    "train_ds = Dataset.from_pandas(train_df[[\"text\", \"target\"]])\n",
    "val_ds = Dataset.from_pandas(val_df[[\"text\", \"target\"]])\n",
    "test_ds = Dataset.from_pandas(test_df[[\"text\", \"target\"]])\n",
    "\n",
    "# Tokenize the datasets\n",
    "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
    "tokenized_val = val_ds.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "# Drop the text column after tokenization\n",
    "tokenized_train = tokenized_train.remove_columns(['text'])\n",
    "tokenized_val = tokenized_val.remove_columns(['text'])\n",
    "tokenized_test = tokenized_test.remove_columns(['text'])\n",
    "\n",
    "# Initialize the data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Variables to store metrics and predictions\n",
    "acc = []\n",
    "f1 = []\n",
    "idx = []\n",
    "preds = pd.DataFrame()\n",
    "\n",
    "# Train the model for different experiments\n",
    "for i in range(3, 4):\n",
    "    idx.append(i)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/bert/bert-task1-exp-{i}',\n",
    "        per_device_train_batch_size=32,\n",
    "        num_train_epochs=15,\n",
    "        learning_rate=0.00005,\n",
    "        evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "        save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "        load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "        metric_for_best_model=\"f1\"    # Use F1 score to determine the best model\n",
    "    )\n",
    "\n",
    "    # Trainer object initialization\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Validation Results: {eval_results}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_results = trainer.predict(tokenized_test)\n",
    "    print(f\"Test Results: {test_results.metrics}\")\n",
    "\n",
    "    # Detailed classification report\n",
    "    test_preds = np.argmax(test_results.predictions, axis=1)\n",
    "    test_labels = test_results.label_ids\n",
    "    print(classification_report(test_labels, test_preds))\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(f\"./models_bayes/bert-task1-exp-{i}\")\n",
    "\n",
    "    # Make predictions on validation set\n",
    "    pred = trainer.predict(tokenized_val)\n",
    "    pred_train = trainer.predict(tokenized_train)\n",
    "\n",
    "    preds_test = pd.DataFrame(np.concatenate([softmax(pred.predictions, axis=1), pred.label_ids.reshape((-1, 1))], axis=1), columns=['0', '1', '2', 'label'])\n",
    "    preds_train = pd.DataFrame(np.concatenate([softmax(pred_train.predictions, axis=1), pred_train.label_ids.reshape((-1, 1))], axis=1), columns=['0', '1', '2', 'label'])\n",
    "    preds_test.to_csv(f\"./predictions_bayes/bert-task1-exp-{i}-preds-val.csv\", index=False)\n",
    "    preds_train.to_csv(f\"./predictions_bayes/bert-task1-exp-{i}-preds-train.csv\", index=False)\n",
    "\n",
    "    model_predictions = np.argmax(softmax(pred.predictions, axis=1), axis=1)\n",
    "    preds[\"target\"] = model_predictions\n",
    "    preds.to_csv(f\"./predictions_bayes/bert-task1-exp-{i}-preds.csv\", index=False)\n",
    "\n",
    "    # Store metrics\n",
    "    acc.append(eval_results['eval_accuracy'])\n",
    "    f1.append(eval_results['eval_f1'])\n",
    "\n",
    "# Print overall results\n",
    "print(\"\\nOverall Results:\")\n",
    "for i, (accuracy, f1_score) in enumerate(zip(acc, f1), start=3):\n",
    "    print(f\"Experiment {i}: Accuracy = {accuracy:.4f}, F1 Score = {f1_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
